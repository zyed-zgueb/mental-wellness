"""Gestionnaire de conversations avec l'API Claude."""

import os
from typing import Generator, List, Dict
from anthropic import Anthropic
import anthropic
from src.database.db_manager import DatabaseManager
from src.utils.prompts import CONVERSATION_SYSTEM_PROMPT, CRISIS_KEYWORDS


class ConversationManager:
    """Gestionnaire de conversations avec Claude API."""

    # Configuration de la gestion du contexte
    MAX_CONTEXT_TOKENS = 180000  # Limite de s√©curit√© (Claude-4 supporte 200k)
    MAX_HISTORY_MESSAGES = 50  # Nombre maximum de messages √† r√©cup√©rer
    MIN_RECENT_MESSAGES = 10  # Toujours garder les N derniers messages

    def __init__(self, db_manager: DatabaseManager, enable_action_extraction: bool = True):
        """
        Initialiser le gestionnaire de conversations.

        Args:
            db_manager: Instance de DatabaseManager pour la persistance.
            enable_action_extraction: Activer l'extraction automatique d'actions (d√©faut: True).

        Raises:
            ValueError: Si ANTHROPIC_API_KEY n'est pas d√©finie.
        """
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment")

        self.client = Anthropic(api_key=api_key)
        self.db = db_manager
        self.system_prompt = CONVERSATION_SYSTEM_PROMPT
        self.enable_action_extraction = enable_action_extraction
        self.action_extractor = None

        # Lazy load action extractor pour √©viter import circulaire
        if enable_action_extraction:
            from src.llm.action_extractor import ActionExtractor
            self.action_extractor = ActionExtractor(db_manager)

    def _estimate_tokens(self, text: str) -> int:
        """
        Estimer le nombre de tokens dans un texte.

        R√®gle approximative : ~4 caract√®res = 1 token pour le fran√ßais.

        Args:
            text: Texte √† analyser.

        Returns:
            Nombre estim√© de tokens.
        """
        return len(text) // 4

    def _build_conversation_context(self, user_id: int, current_message: str) -> List[Dict[str, str]]:
        """
        Construire le contexte de conversation avec gestion intelligente de la limite de tokens.

        Args:
            user_id: ID de l'utilisateur.
            current_message: Message actuel de l'utilisateur.

        Returns:
            Liste de messages format√©s pour l'API Claude (role + content).
        """
        # R√©cup√©rer l'historique depuis la base de donn√©es
        history = self.db.get_conversation_history(user_id, limit=self.MAX_HISTORY_MESSAGES)

        # Construire les messages altern√©s user/assistant
        messages = []
        cumulative_tokens = self._estimate_tokens(self.system_prompt)

        for conv in history:
            user_msg = {"role": "user", "content": conv['user_message']}
            assistant_msg = {"role": "assistant", "content": conv['ai_response']}

            # Estimer les tokens pour ces messages
            msg_tokens = self._estimate_tokens(conv['user_message']) + \
                        self._estimate_tokens(conv['ai_response'])

            # V√©rifier si on peut ajouter ces messages sans d√©passer la limite
            if cumulative_tokens + msg_tokens < self.MAX_CONTEXT_TOKENS or \
               len(messages) < self.MIN_RECENT_MESSAGES * 2:  # Toujours garder minimum messages
                messages.append(user_msg)
                messages.append(assistant_msg)
                cumulative_tokens += msg_tokens
            else:
                # On a atteint la limite, arr√™ter d'ajouter des messages plus anciens
                break

        # Ajouter le message actuel
        current_tokens = self._estimate_tokens(current_message)
        messages.append({"role": "user", "content": current_message})
        cumulative_tokens += current_tokens

        # Log pour debugging (optionnel)
        print(f"üìä Contexte construit: {len(messages)} messages, ~{cumulative_tokens} tokens estim√©s")

        return messages

    def send_message(self, user_id: int, user_message: str) -> Generator[str, None, None]:
        """
        Envoyer un message √† Claude avec streaming et contexte complet.

        Args:
            user_id: ID de l'utilisateur.
            user_message: Message de l'utilisateur.

        Yields:
            Chunks de texte de la r√©ponse (streaming).

        Raises:
            Exception: En cas d'erreur API (retourne message d'erreur convivial).
        """
        try:
            # Construire le contexte complet de la conversation
            messages = self._build_conversation_context(user_id, user_message)

            # Envoyer avec l'historique complet
            with self.client.messages.stream(
                model="claude-sonnet-4-20250514",
                max_tokens=2048,  # Augment√© pour des r√©ponses plus compl√®tes
                system=self.system_prompt,
                messages=messages  # ‚úÖ Contexte complet !
            ) as stream:
                response_text = ""
                for text in stream.text_stream:
                    response_text += text
                    yield text

                # Sauvegarder apr√®s compl√©tion
                usage = stream.get_final_message().usage
                tokens = usage.input_tokens + usage.output_tokens
                conversation_id = self.db.save_conversation(
                    user_id, user_message, response_text, tokens
                )

                # Extraire les actions automatiquement
                if self.enable_action_extraction and self.action_extractor:
                    try:
                        self.action_extractor.extract_actions_from_message(
                            user_message, user_id, conversation_id
                        )
                    except Exception as e:
                        print(f"Erreur extraction d'actions: {e}")
                        # Ne pas bloquer la conversation si l'extraction √©choue

        except Exception as e:
            error_msg = "Je suis d√©sol√©, je rencontre des difficult√©s techniques. Veuillez r√©essayer."
            # Log l'erreur pour debugging
            print(f"API Error: {e}")
            yield error_msg

    def detect_crisis(self, message: str) -> bool:
        """
        D√©tecter les mots-cl√©s de crise dans un message.

        Args:
            message: Message de l'utilisateur.

        Returns:
            True si un mot-cl√© de crise est d√©tect√©, False sinon.
        """
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in CRISIS_KEYWORDS)
